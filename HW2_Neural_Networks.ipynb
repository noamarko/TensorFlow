{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2_Neural_Networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noamarko/Neural-Networks/blob/main/HW2_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrIiMBpNmeVq"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9AS8qInmqbr"
      },
      "source": [
        "def BTU_layer(x, w, b, Temp = 0.1):    \n",
        "  z = tf.matmul(x, w) + b\n",
        "  return tf.nn.sigmoid(z / Temp) "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0H_yAP2msnr"
      },
      "source": [
        "class XOR_Net_Model:\n",
        "  def __init__(self, input_dim, num_hidden, num_hbridge, num_outputs, ShortCut):\n",
        "    self.w1 = tf.Variable(tf.random.uniform([dim, num_hidden], -1, 1, seed=0), name=\"weights1\", trainable=True)\n",
        "    self.w2 = tf.Variable(tf.random.uniform([num_hbridge, num_outputs], -1, 1, seed=0), name=\"weights2\", trainable=True)\n",
        "    self.b1 = tf.Variable(tf.zeros([num_hidden]), name=\"bias1\", trainable=True)\n",
        "    self.b2 = tf.Variable(tf.zeros([num_outputs]), name=\"bias2\", trainable=True)\n",
        "    self.ShortCut = ShortCut\n",
        "    \n",
        "  # feed forward\n",
        "  def __call__(self, x_train):\n",
        "    self.hlayer1 = BTU_layer(x_train, self.w1, self.b1)\n",
        "    if self.ShortCut:\n",
        "        self.hlayer1 = tf.concat([self.hlayer1, x_train], 1)\n",
        "    self.out = BTU_layer(self.hlayer1, self.w2, self.b2)\n",
        "    return self.out"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBavtW8mmu0n"
      },
      "source": [
        "# compute loss on feed forward step\n",
        "def Loss(out, t_train):\n",
        "  loss = -tf.reduce_sum(t_train * tf.math.log(out) + (1.0 - t_train) * tf.math.log(1.0 - out))  # Cross Entropy loss function\n",
        "  return tf.divide(loss, len(out), name=\"loss\")\n",
        "# compute grads for back propagation\n",
        "def grad(model, x_train, t_train):\n",
        "  with tf.GradientTape() as t:\n",
        "    loss = Loss(model(x_train), t_train)\n",
        "  return t.gradient(loss, [model.w1, model.b1, model.w2, model.b2]), loss"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFlUpYTboHN1"
      },
      "source": [
        "# 1 train step operation\n",
        "def epoch(model, x_train, t_train, optimizer):\n",
        "  grads, loss = grad(model, x_train, t_train)\n",
        "  optimizer.apply_gradients(zip(grads, [model.w1, model.b1, model.w2, model.b2]))\n",
        "  return loss"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZXlgkVKoLLe"
      },
      "source": [
        "# run training:\n",
        "def train(model, x_train, t_train, optimizer, x_test, t_test, num_epochs):\n",
        "  ten_last_losses = [np.Infinity]*10 #array that will check if the condition = true\n",
        "  i = 0\n",
        "  for i in range(num_epochs+1):\n",
        "    train_loss = epoch(model, x_train, t_train, optimizer).numpy()\n",
        "    valid_loss = Loss(model(x_test), t_test).numpy()\n",
        "    #if i % 1000 == 0:\n",
        "    #  print(\"\\n Valid Loss: \", valid_loss)  \n",
        "    ten_last_losses[i%10] = valid_loss\n",
        "    if tf.math.is_nan(valid_loss):\n",
        "      return i, valid_loss, -1\n",
        "    if i >= 9 and (valid_loss < 0.2) and (ten_last_losses[(i+1)%10] -  ten_last_losses[i%10]) < 0.0001:\n",
        "      return i, valid_loss, train_loss\n",
        "  return i,valid_loss,-1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh6ULlZGeElU"
      },
      "source": [
        "def test(model, x_test, t_test):\n",
        "  loss = Loss(model(x_test), t_test)\n",
        "  return loss"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTejEyUc1x_c"
      },
      "source": [
        "def start_exp(dim, num_hidden, num_outputs, l_rate, ShortCut, num_epochs):\n",
        "  \n",
        "  epochs = []\n",
        "  v_losses = []\n",
        "  t_losses = []\n",
        "  i = 0\n",
        "  fail = 0\n",
        "  while i < 10:\n",
        "    if ShortCut:\n",
        "        num_hbridge = num_hidden + dim\n",
        "    else:\n",
        "        num_hbridge = num_hidden\n",
        "    # define a model:\n",
        "    model = XOR_Net_Model(dim, num_hidden, num_hbridge, num_outputs, ShortCut)\n",
        "    # set an optimizer:\n",
        "    optimizer = tf.compat.v1.train.GradientDescentOptimizer(l_rate)\n",
        "    #defining the train group and the validation group\n",
        "    x_train = tf.convert_to_tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=tf.float32)\n",
        "    t_train = tf.convert_to_tensor([[0], [1], [1], [0]], dtype=tf.float32)\n",
        "    x_test = tf.convert_to_tensor([[0, 0], [0, 1], [1, 0], [1, 1], [1, 0.1], [1, 0.9], [0.9,0.9], [0.1, 0.9]], dtype=tf.float32)\n",
        "    t_test = tf.convert_to_tensor([[0], [1], [1], [0], [1], [0], [0], [1]], dtype=tf.float32)\n",
        "    num, CE_test, CE_train  = train(model, x_train, t_train, optimizer, x_test, t_test, num_epochs)\n",
        "    if num != num_epochs and i<10 and np.logical_not(tf.math.is_nan(CE_test)):\n",
        "      epochs.append(num)\n",
        "      v_losses.append(CE_test)\n",
        "      t_losses.append(CE_train)\n",
        "      i += 1\n",
        "      if num_hidden == 1:\n",
        "        print(model.hlayer1)\n",
        "    else:\n",
        "      fail += 1\n",
        "    \n",
        "  mean_v = np.mean(v_losses)\n",
        "  mean_t = np.mean(t_losses)\n",
        "  mean_e = np.mean(epochs)\n",
        "  std_v = np.std(v_losses)\n",
        "  std_t = np.std(t_losses)\n",
        "  std_e = np.std(epochs)\n",
        "\n",
        "  print(\"\\nmeanepocs: {},          std/epocs: {},   Failures: {}\".format(mean_e, std_e, fail))\n",
        "  print(\"\\nmeanvalidloss: {},      stdvalidlossPercent: {}\".format(mean_v, std_v))\n",
        "  print(\"\\nnmeanTrainLoss: {},     stdTrainLossPercent: {}\".format(mean_t, std_t))\n",
        "  return mean_e, std_e "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yMGdpayacej"
      },
      "source": [
        "## Expirement 1:\n",
        "Hidden Neurons: 2\n",
        "\n",
        "Learning Rate: 0.1\n",
        "\n",
        "Short Cut: True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g6go87Pab-b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38a21df5-cd7d-4c0b-b892-62580206c15e"
      },
      "source": [
        "epoch_mean = []\n",
        "epoch_std = []\n",
        "learning_r = []\n",
        "hidden_n = []\n",
        "bridge = []\n",
        "dim = 2\n",
        "num_hidden = 2\n",
        "num_outputs = 1\n",
        "l_rate = 0.1\n",
        "ShortCut = True\n",
        "num_epochs = 40000\n",
        "print(\"Expirement 1:  Hidden: {},  LR: {},  Bridge: {}\".format(num_hidden, l_rate, ShortCut))\n",
        "ep_m, ep_std = start_exp(dim, num_hidden, num_outputs, l_rate, ShortCut, num_epochs)\n",
        "epoch_mean.append(ep_m)\n",
        "epoch_std.append(ep_std)\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expirement 1:  Hidden: 2,  LR: 0.1,  Bridge: True\n",
            "\n",
            "meanepocs: 499.7,          std/epocs: 108.75941338569274,   Failures: 1\n",
            "\n",
            "meanvalidloss: 0.00695795938372612,      stdvalidlossPercent: 0.0017819652566686273\n",
            "\n",
            "nmeanTrainLoss: 0.003166498616337776,     stdTrainLossPercent: 0.00040444982005283237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kfX-5QfAMNV"
      },
      "source": [
        "## Expirement 2:\n",
        "Hidden Neurons: 2\n",
        "\n",
        "Learning Rate: 0.1\n",
        "\n",
        "Short Cut:  False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfAoXMqndKSy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba645c39-8413-4de1-c0c0-b8c487347357"
      },
      "source": [
        "dim = 2\n",
        "num_hidden = 2\n",
        "num_outputs = 1\n",
        "l_rate = 0.1\n",
        "ShortCut = False\n",
        "num_epochs = 40000\n",
        "print(\"Expirement 2:  Hidden: {},  LR: {},  Bridge: {}\".format(num_hidden, l_rate, ShortCut))\n",
        "ep_m, ep_std = start_exp(dim, num_hidden, num_outputs, l_rate, ShortCut, num_epochs)\n",
        "epoch_mean.append(ep_m)\n",
        "epoch_std.append(ep_std)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expirement 2:  Hidden: 2,  LR: 0.1,  Bridge: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Dq-sOi_N7rp"
      },
      "source": [
        "## Expirement 3:\n",
        "Hidden Neurons: 2\n",
        "\n",
        "Learning Rate: 0.01\n",
        "\n",
        "Short Cut: True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaI7USLHN65c"
      },
      "source": [
        "dim = 2\n",
        "num_hidden = 2\n",
        "num_outputs = 1\n",
        "l_rate = 0.01\n",
        "ShortCut = True\n",
        "num_epochs = 40000\n",
        "print(\"Expirement 3:  Hidden: {},  LR: {},  Bridge: {}\".format(num_hidden, l_rate, ShortCut))\n",
        "ep_m, ep_std = start_exp(dim, num_hidden, num_outputs, l_rate, ShortCut, num_epochs)\n",
        "epoch_mean.append(ep_m)\n",
        "epoch_std.append(ep_std)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt2jUtodVUwH"
      },
      "source": [
        "## Expirement 4:\n",
        "Hidden Neurons: 2\n",
        "\n",
        "Learning Rate: 0.01\n",
        "\n",
        "Short Cut: False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg6GV1tSVwmf"
      },
      "source": [
        "dim = 2\n",
        "num_hidden = 2\n",
        "num_outputs = 1\n",
        "l_rate = 0.01\n",
        "ShortCut = False\n",
        "num_epochs = 40000\n",
        "print(\"Expirement 4:  Hidden: {},  LR: {},  Bridge: {}\".format(num_hidden, l_rate, ShortCut))\n",
        "ep_m, ep_std = start_exp(dim, num_hidden, num_outputs, l_rate, ShortCut, num_epochs)\n",
        "epoch_mean.append(ep_m)\n",
        "epoch_std.append(ep_std)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbpbH4sKV0VK"
      },
      "source": [
        "## Expirement 5:\n",
        "Hidden Neurons: 4\n",
        "\n",
        "Learning Rate: 0.1\n",
        "\n",
        "Short Cut: True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LR7jYTFVzp3"
      },
      "source": [
        "dim = 2\n",
        "num_hidden = 4\n",
        "num_outputs = 1\n",
        "l_rate = 0.1\n",
        "ShortCut = True\n",
        "num_epochs = 40000\n",
        "print(\"Expirement 5:  Hidden: {},  LR: {},  Bridge: {}\".format(num_hidden, l_rate, ShortCut))\n",
        "ep_m, ep_std = start_exp(dim, num_hidden, num_outputs, l_rate, ShortCut, num_epochs)\n",
        "epoch_mean.append(ep_m)\n",
        "epoch_std.append(ep_std)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVN5cckZWVVJ"
      },
      "source": [
        "## Expirement 6:\n",
        "Hidden Neurons: 4\n",
        "\n",
        "Learning Rate: 0.1\n",
        "\n",
        "Short Cut: False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBk8V3sUWbmt"
      },
      "source": [
        "dim = 2\n",
        "num_hidden = 4\n",
        "num_outputs = 1\n",
        "l_rate = 0.1\n",
        "ShortCut = False\n",
        "num_epochs = 40000\n",
        "print(\"Expirement 6:  Hidden: {},  LR: {},  Bridge: {}\".format(num_hidden, l_rate, ShortCut))\n",
        "ep_m, ep_std = start_exp(dim, num_hidden, num_outputs, l_rate, ShortCut, num_epochs)\n",
        "epoch_mean.append(ep_m)\n",
        "epoch_std.append(ep_std)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Tx8pdS3WeX3"
      },
      "source": [
        "## Expirement 7:\n",
        "Hidden Neurons: 4\n",
        "\n",
        "Learning Rate: 0.01\n",
        "\n",
        "Short Cut: True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9UtFytOWjhi"
      },
      "source": [
        "dim = 2\n",
        "num_hidden = 4\n",
        "num_outputs = 1\n",
        "l_rate = 0.01\n",
        "ShortCut = True\n",
        "num_epochs = 40000\n",
        "print(\"Expirement 7:  Hidden: {},  LR: {},  Bridge: {}\".format(num_hidden, l_rate, ShortCut))\n",
        "ep_m, ep_std = start_exp(dim, num_hidden, num_outputs, l_rate, ShortCut, num_epochs)\n",
        "epoch_mean.append(ep_m)\n",
        "epoch_std.append(ep_std)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGv6hF4oWj_v"
      },
      "source": [
        "## Expirement 8:\n",
        "Hidden Neurons: 4\n",
        "\n",
        "Learning Rate: 0.01\n",
        "\n",
        "Short Cut: False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWv5AP1lWtmP"
      },
      "source": [
        "dim = 2\n",
        "num_hidden = 4\n",
        "num_outputs = 1\n",
        "l_rate = 0.01\n",
        "ShortCut = False\n",
        "num_epochs = 40000\n",
        "print(\"Expirement 8:  Hidden: {},  LR: {},  Bridge: {}\".format(num_hidden, l_rate, ShortCut))\n",
        "ep_m, ep_std = start_exp(dim, num_hidden, num_outputs, l_rate, ShortCut, num_epochs)\n",
        "epoch_mean.append(ep_m)\n",
        "epoch_std.append(ep_std)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSIaAr6wWuXY"
      },
      "source": [
        "## Expirement 9:\n",
        "Hidden Neurons: 1\n",
        "\n",
        "Learning Rate: 0.01\n",
        "\n",
        "Short Cut: True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MDJ-vttX53M"
      },
      "source": [
        "dim = 2\n",
        "num_hidden = 1\n",
        "num_outputs = 1\n",
        "l_rate = 0.01\n",
        "ShortCut = True\n",
        "num_epochs = 40000\n",
        "print(\"Expirement 9:  Hidden: {},  LR: {},  Bridge: {}\".format(num_hidden, l_rate, ShortCut))\n",
        "ep_m, ep_std = start_exp(dim, num_hidden, num_outputs, l_rate, ShortCut, num_epochs)\n",
        "epoch_mean.append(ep_m)\n",
        "epoch_std.append(ep_std)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lPkoepHV8pa"
      },
      "source": [
        "## Creating Graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoXuzV_DWAlp"
      },
      "source": [
        "## 1. Epoch mean by number of hidden Neurons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvQp4IwGPAdy"
      },
      "source": [
        "epoch_oneh = epoch_mean[8]\n",
        "epoch_twoh = np.mean([epoch_mean[0], epoch_mean[1], epoch_mean[2], epoch_mean[3]])\n",
        "epoch_fourh = np.mean([epoch_mean[4], epoch_mean[5], epoch_mean[6], epoch_mean[7]])\n",
        "plt.axis([0, 4, 300, 4500])\n",
        "plt.yscale('linear')\n",
        "plt.ylabel('Epoch Means')\n",
        "plt.xlabel('Hidden Neurons')\n",
        "plt.plot([1, 2, 4] , [epoch_oneh, epoch_twoh, epoch_fourh])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tuVN-TvWIid"
      },
      "source": [
        "## 2. Epoch mean by existence of bridge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEZJPepZbSQo"
      },
      "source": [
        "epochs_bridge = np.mean([epoch_mean[0], epoch_mean[2],epoch_mean[4], epoch_mean[6], epoch_mean[8]])\n",
        "epochs_no_bridge = np.mean([epoch_mean[1], epoch_mean[3], epoch_mean[5], epoch_mean[7]])\n",
        "df = pd.DataFrame({'Bridge':['Bridge', 'Without Bridge'], 'Epochs Mean':[epochs_bridge, epochs_no_bridge]})\n",
        "ax = sns.barplot(x=\"Bridge\", y=\"Epochs Mean\", data=df)\n",
        "ax.set_ylim([0, 2000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2y79ISlnWON2"
      },
      "source": [
        "## 3. Epoch std by learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d55tHCmUs8J"
      },
      "source": [
        "epochs_std_01 = np.mean([epoch_std[0],\n",
        "                         epoch_std[1],\n",
        "                         epoch_std[4],\n",
        "                         epoch_std[5]])\n",
        "epochs_std_001 = np.mean([epoch_std[2],\n",
        "                          epoch_std[3],\n",
        "                          epoch_std[6],\n",
        "                          epoch_std[7],\n",
        "                          epoch_std[8]])\n",
        "df = pd.DataFrame({'Learning Rate': [0.1, 0.01], 'STD of Epochs':[epochs_std_01, \n",
        "                                                                  epochs_std_001]})\n",
        "ax = sns.barplot(x = \"Learning Rate\", y = \"STD of Epochs\", data = df)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}